# Aquifer depletion exacerbates agricultural drought losses in the US High Plains

## Instruction for Reproducing the Results and Figures

Here is the breakdown of the steps of completing the project.

1. Download and process datasets
2. Combine the processed datasets
3. Conduct analysis and create figures
4. Produce the manuscript

## Step 1: Download codes 

Download the computer programs from this repository. You can either clone or download the files as a zipped folder into the root folder. Then, create a folder named "Results". If done correctly, the folder system looks like this.

![folder-structure](https://github.com/tmieno2/Drought-Production-Risk-Aquifer/blob/master/Misc/folder-structure.png)

## Step 2: Download datasets

Datasets for this project are stored in two separate places. 

1. figshare (DOI: 10.6084/m9.figshare.24492196)
2. [Dropbox folder](https://www.dropbox.com/scl/fo/bghhwlidmi7wx1ok0az5n/h?rlkey=tgbix1hp7g9np9etlo1z3biyr&dl=0)

Which one to use depends on the depth of reproduction you would like to achieve.  

The "official" data storage for the article is hosted on the figshare data repository. However, due to constraints on file number and size, the repository does not include all files generated by our computer programs. For a comprehensive list of datasets produced during this research project, please refer to the metadata.html within the repository. Specifically, the repository lacks the daily gridMET datasets, annual saturated thickness data, and individual SSURGO county data. It's essential to emphasize that all critical datasets required to replicate the results and figures reported in the article are available in the repository. That is, you can execute steps 2, 3, and 4 utilizing data from this source. That said, our research files are organized into two folders (data-raw and data-processed) in our project folder, and our computer codes anticipate this structure. If you intend to run our codes, you either need to replicate this directory setup by manually creating the folders and positioning the files appropriately or adjust the file paths in our codes.

For a more straightforward experience, our Dropbox folder houses all project datasets, including raw data and metadata. Importantly, it maintains the folder organization and file locations as employed during our project's execution. This avoids the potential complications linked with the figshare repository. If your focus is solely on steps 2, 3, and 4, downloading the data-processed folder will suffice. However, if you aim to reproduce the entire process, from start to finish (steps 1 through 4), you'll need the data-raw folder. It's worth noting that the **gridMET** folder inside the **data-raw** folder, containing daily weather data files sorted by variable-year, is particularly large, weighing in at roughly 37GB. While our codes include a segment to download this data, if you'd prefer bypassing this potentially time-consuming step, downloading the folder directly is an option â€” provided you're comfortable with its size.

All the data files should be stored in the Data folder (which you should create). The ideal folder structure looks like below:

![folder-structure](https://github.com/tmieno2/Drought-Production-Risk-Aquifer/blob/master/Misc/folder-structure-with-data.png)

## Step 3: Install all the R packages

The root folder is set up as an RStudio project. 

+ Open the project on RStudio
+ Run `renv::restore()` (install the `renv` packages first, if you have not done so). This will install all the R packages used for this project. Note that the packages installed here are specific to this project. See [here](https://rstudio.github.io/renv/articles/renv.html) for an introduction of how to use the `renv` package.

Codes to load the packages are in the **.Rprofile** file. This file is run automatically when you open the project. Since you did not have all the R packages for this project, they were not loaded when you first open the project to set things up as outlined above. So, go to Session -> Restart R to restart an R session, which will run **.Rprofile** again and now you have all the packages loaded. Next time you start the project, you do not have to do anything. The codes will be ready to be run.

## Step 4: Run codes

Open **master.rmd** inside the **Codes** folder.

+ **Reproduce every step of the project**: Run the codes from the top (This takes a while and uses up lots of storage memory). 
+ **Reproduce from step 2 on**: Run the codes starting from line 47.
+ **Reproduce from step 3 on**: Run the codes starting from line 53.

Please note that our team utilizes Rmarkdown (.rmd) files for coding. The master.rmd initially converts the Rmarkdown files into R files using `knitr::purl()`, and subsequently `source()` them. If you wish to work on a particular process, refer to the corresponding Rmarkdown file rather than the associated R file. This is because the latter is not as well-organized since `knitr::purl()` strips all the section headers and non-R texts.

