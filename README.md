# Aquifer depletion exacerbates agricultural drought losses in the US High Plains (Nature Water)

## Instruction for Reproducing the Results and Figures

Here is the breakdown of the steps of completing the project.

1. Download and process datasets
2. Combine the process datasets
3. Conduct analysis and create figures
4. Produce the manuscript

## Step 1: Download codes 

Download the computer programs from the [GitHub repository](https://github.com/tmieno2/Drought-Production-Risk-Aquifer) (https://github.com/tmieno2/Drought-Production-Risk-Aquifer). You can either clone or download the files as a zipped folder into the root folder. Then, create a folder named "Results". If done correctly, the folder system looks like this.

![folder-structure](https://github.com/tmieno2/Drought-Production-Risk-Aquifer/blob/master/Misc/folder-structure.png)

## Step 2: Download datasets

Datasets for this project are stored in two separate places. 

1. figshare (DOI: 10.6084/m9.figshare.24492196)
2. [Dropbox folder](https://www.dropbox.com/scl/fo/bghhwlidmi7wx1ok0az5n/h?rlkey=tgbix1hp7g9np9etlo1z3biyr&dl=0)

Which one to use depends on the depth of reproduction you would like to achieve.  

The "official" data storage for the article is hosted on the figshare data repository. However, due to constraints on file number and size, the repository does not include all files generated by our computer programs. For a comprehensive list of datasets produced during this research project, please refer to the metadata.html within the repository. Specifically, the repository lacks the daily gridMET datasets, annual saturated thickness data, and individual SSURGO county data. It's essential to emphasize that all critical datasets required to replicate the results and figures reported in the article are available in the repository. That is, you can execute steps 2, 3, and 4 utilizing data from this source. That said, our research files are organized into two folders (data-raw and data-processed) in our project folder, and our computer codes anticipate this structure. If you intend to run our codes, you either need to replicate this directory setup by manually creating the folders and positioning the files appropriately or adjust the file paths in our codes.

For a more straightforward experience, our Dropbox folder houses all project datasets, including raw data and metadata. Importantly, it maintains the folder organization and file locations as employed during our project's execution. This avoids the potential complications linked with the figshare repository. If your focus is solely on steps 2, 3, and 4, downloading the data-processed folder will suffice. However, if you aim to reproduce the entire process, from start to finish (steps 1 through 4), you'll need the data-raw folder. It's worth noting that the gridMET folder, containing daily weather data files sorted by variable-year, is particularly large, weighing in at roughly 37GB. While our codes include a segment to download this data, if you'd prefer bypassing this potentially time-consuming step, downloading the folder directly is an option â€” provided you're comfortable with its size.

All the data files should be stored in the Data folder (which you should create). The ideal folder structure looks like below:

![folder-structure](https://github.com/tmieno2/Drought-Production-Risk-Aquifer/blob/master/Misc/folder-structure-with-data.png)

## Step 3: Run codes

The root folder is set up as an RStudio project. You can open the project on RStudio and open **master.rmd** inside the **Codes** folder.

+ **Reproduce every step of the project**: Run the codes from the top (This takes a while and use up lots of storage memory). 
+ **Reproduce from step 2 on**: Run the codes starting from the Analysis section.


